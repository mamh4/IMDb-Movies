```{r libraries, echo = FALSE, message = FALSE}
source(here::here("scripts/setup.R"))
#libraries
library(ggplot2)
library(scales) # for comma separators
library(patchwork)
library(dplyr)
library(mgcv) # to predict population between census years
library(magrittr) #for the dot operator
library(lubridate)
```

# Data

IMDb has been around since 1990 and has a long history of collecting movie ratings and reviews. Over the years, it has built a substantial database of user-contributed content. IMDb makes its rating and review system transparent. Users can see how many people have rated a movie and read individual reviews. This openness adds to its credibility. 

To address our research inquiry, we gathered information from IMDb, specifically from the following [webpage](https://www.imdb.com/search/title/?title_type=feature&num_votes=0,&sort=user_rating,desc&ref_=adv_prv). Subsequently, we enhanced this data set by incorporating data from Wikipedia, the U.S. Bureau of Labor, and the U.S. Census Bureau. We offer a comprehensive presentation of the amalgamated data set below.

TODO: Tables (incl. footnote on gross amount being only US)

As of October 21, 2023, the data set on featured movies comprises a total of 247,739 movie titles. These films have been rated by IMDb users who have registered on the platform. The count of ratings within this data set ranges from just a handful up to millions (<3 million).

```{r cut-off-decision}
# Scrape movies
source("../scripts/scrapping_functions/scrape_movies.R")
movies <- scrape_movies(n=25,10000,TRUE) #TO BE REMOVED
#movies <- scrape_movies(n_start=1, n_end=10,min_number_votes = 10000, print_progress = FALSE, return_next_url = FALSE, start_url = 'empty')
load("../data/cleaned_data/full_IMDb_Scrape.Rdata")#data name movies

# set NA number of votes to 0 (Two movies with NA votes from IMDb featured page, however <50 votes on IMDb movie page)
movies[is.na(movies$votes) & movies$title == "Ein Fest fÃ¼rs Leben","votes"] <- 9
movies[is.na(movies$votes) & movies$title == "Building Heaven, Remembering Earth","votes"] <- 16

#Pick a cut-off point
a <- movies |>
  mutate(bin = (votes %/% 250+1)*250 ) |> #bin size of 250
  select(bin,rating) |> 
  group_by(bin) |>
  summarise(avg_rating = mean(rating,na.rm = T)) |>
  ggplot(aes(x=bin,y=avg_rating))+
  labs(title = "A logarithmic trend can be observed after excluding movies\nwith less than 10k votes"
       ,x="Number of Votes", y = "Average Rating") +
  geom_point()+
  geom_smooth()+
  scale_x_continuous(breaks = seq(0,3e6,600000),labels = scales::comma )+
  scale_y_continuous(limits = c(0,10),breaks = seq(0,10,2))+
  theme_minimal()


b <- movies |>
  mutate(bin = (votes %/% 250+1)*250 ) |> #bin size of 250
  select(bin,rating) |> 
  group_by(bin) |>
  summarise(avg_rating = mean(rating,na.rm = T)) |>
  ggplot(aes(x=bin,y=avg_rating))+
  labs(x="Number of Votes", y = "Average Rating") +
  geom_point()+
  geom_point(col="red",data = movies |>
                              mutate(bin = (votes %/% 250+1)*250 ) |> #bin size of 250
                              select(bin,rating) |> 
                              group_by(bin) |>
                              summarise(avg_rating = mean(rating,na.rm = T)) |>
                              filter(bin<=10000))+
  geom_smooth()+
  coord_cartesian(xlim = c(0, 180000))+
  scale_y_continuous(limits = c(0,10),breaks = seq(0,10,2))+
  geom_vline(xintercept = 10000,linetype = "dashed")+
  scale_x_continuous(labels = scales::comma)+
  annotate("text", x = 10000, y = 10, vjust = "top", hjust = "left",
           label = "10k")+
  theme_minimal()
  
(a | b)

```
Conclusion: cut-off at 10k


Now that we decided on the cut-off of 10k we end up with 10,555 movie titles which we try to enrich with information such as the date of births of actors and directors the studio(s) that produced the film and the budget. Since we have movies dating back from 1900s we decided to include the average annual consumer price index and population estimates.


```{r data-enrichment, echo = FALSE, message = FALSE}
# Read other data | You can replace the loading with reading function or sourcing to run on a new data set! For instance try the movies / dob / studio and budget enrichment functions! Note however that some of those functions (scraping/cleaning) may take quite long but usually they are pretty quick for low data such as 25 movies or so.
# Code replacements are commented just above their respective functions.



movies <- movies |>
  filter(votes>=10000)


# Source relevant scripts
source("../scripts/scrapping_functions/enrich_dob.R")
source("../scripts/scrapping_functions/enrich_studio_and_budget.R")


# Load and aggregate data switch load with functions to try on new data set

#dob_table_stars_cleaned <- find_dob( movies |> select(stars) |>
#                       separate_rows(stars, sep = ",\\s*")|>
#                       unique()) |> mutate(dob_stars = ymd(dob))
load("../data/cleaned_data/dob_stars10k_cleaned.Rdata")


#dob_table_directors_cleaned <- find_dob( movies |> select(directors) |>
#                        separate_rows(directors, sep = ",\\s*")|> 
#                        unique()) |> mutate(dob_directors = ymd(dob))
load("../data/cleaned_data/dob_directors10k_cleaned.Rdata")


#studio_and_budget <- enrich_studio_and_budget(movies[,c("title","year")])
load("../data/scrapped_data/studio_and_budget10k.Rdata")#data name dob_table_directors


#source("../scripts/cleaning_functions/clean_studio_budget.R") #Cleaning the studio takes about 1.5 hours for >10k votes
load("../data/cleaned_data/studio_and_budget10k_cleaned3.Rdata")


# Apparently the dot operator needs %>% not yet implemented in base r using |>
CPI <- read.csv("../data/cleaned_data/inflation.csv") %>%
    mutate(CPI = rowMeans(.[,3:14],na.rm=T)) %>%
    select(Year,CPI) %>%
    rbind(data.frame(Year = 2023,CPI = 302.340)) #US Federal Reserve Economic Data

# integrate population data
population <- read.csv("../data/cleaned_data/population.csv")
population_gam <- gam(population~s(census_year),data = population)
predictions <- predict(object = population_gam, newdata = data.frame(census_year = seq(1900, 2023, 1)))
population_estimates <- data.frame(year = seq(1900, 2023, 1),
                                   population = predictions)


#aggregate data + make it TIDY (Split per per Genre, Actor, Director and Studio)
#Warning is due two films "Beast 2022" when doing a left join, we adjust them afterwards.
suppressWarnings({
movies <- movies |> 
  left_join(CPI,join_by(year==Year)) |>
  left_join(studio_and_budget_cleaned[1:4], join_by(title,year)) |>
  separate_rows(stars, sep = ",\\s*") |>
  left_join(dob_table_stars_cleaned[1:2],join_by(stars)) |>
  separate_rows(directors, sep = ",\\s*") |>
  left_join(dob_table_directors_cleaned[1:2],join_by(directors)) |>
  separate_rows(genre, sep = ",\\s*") |>
  left_join(population_estimates, join_by(year))
})

# There are two movies named beast from the year 2022.
movies[movies$title=="Beast" & movies$run_time ==93,"budget"] <- 36e6
movies[movies$title=="Beast" & movies$run_time ==93,"studio"] <- "Universal Pictures"

```


## Motivation for CPI and population
```{r motivation-cpi-population}
a <- ggplot(population_estimates, aes(year, population)) +
  geom_line() +
  geom_point(aes(x=x,y=y),data = data.frame(x=seq(1900,2025,10), y= population$population))+
  scale_y_continuous(labels = scales::comma) +
  labs(title = "Population and CPI Trend Upwards Over Time", x = "Year", y = "Population") +
  theme_minimal()


b <- ggplot(CPI,aes(Year, CPI))+
  geom_line()+
  labs(x = "Year", y = "CPI") +
  theme_minimal()

(a | b)

```
Since the data is spanning years since the 1900s we thought that including population and Consumer Price Index is crucial for drawing meaningful conclusions. The points on the population plot represent the census years.


## Motivation for data transformation
To relate our research question as close as possible to the data set we have we construct a few estimates, For instance to answer to question How many views a movie received we can approximate it by number of tickets sold and proportion of population who watched the movie.

Furthermore, we notice discrepancy in the certificate column for instance PG meant that viewers of the age of XX could watch the movie with their parents, but in 19XX this changed to XX of age. Therefore we assign the column factor levels that are age dependent.
```{r transformation-chunk, echo = FALSE, message = FALSE}
#integrate transformations of columns into data set.
todays_CPI <- CPI[CPI$Year==2023,"CPI"]
movies$gross_CPI_adjusted <- (movies$gross / movies$CPI)*todays_CPI
movies$budget_CPI_adjusted <- (movies$budget / movies$CPI)*todays_CPI
ticket_price_23 <- 11.15
movies$nr_tickets_sold <- movies$gross_CPI_adjusted / ticket_price_23
movies$profit_CPI_adjusted <- movies$gross_CPI_adjusted - movies$budget_CPI_adjusted

suppressWarnings( # Need to report to Posit, case when returns warning NAs introduced by coercion but this is not true!
movies$certificate_adjusted <- case_when(   # Check Example below
  movies$certificate %in% c("Approved", "G", "GP", "M", "M/PG", "PG") ~ 0,
  movies$certificate == "NC-17" ~ 18,
  is.na(movies$certificate) ~ NA,
  movies$certificate == "Unrated" ~ NA,
  movies$certificate == "Not Rated" ~ NA,
  movies$certificate == "PG-13" ~ 13,
  (movies$year >= 1970 & movies$certificate == "R") ~ 17,
  (movies$year < 1970 & movies$certificate == "R") ~ 16,
  TRUE ~ as.integer(movies$certificate)
))

# Example:
# Need to report to Posit, 'case when' returns warning NAs introduced by coercion but this is not true!
# d <- c("a","b","0")
# a <- case_when(
#  d=="a"~1,
#  d=="b"~2,
#  TRUE~as.numeric(d)
# )


```
Need to mention criticism with the profit metric.


There are 5 "Un Rated" movies and 7 "Not Rated" movies. That we set to NAs. Interstingly the certificate "R" has changed from the age of 16 to 17 post 1970.


