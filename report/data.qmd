# Data

```{r, echo = FALSE, message = FALSE}
source(here::here("scripts/setup.R"))
#libraries
library(ggplot2)
library(patchwork)
library(dplyr)
```

* Sources
* Description
Here we include the table containing the data + mention how we can relate the the variable from the data set we have to the success and success  explanatory variables.


Talk about the large data set and show that it's awful and that we need to pick a cut-off point, we decide the cut-off point based on rating and not meta score or gross as the rating values as feel like it's more robust?
```{r}
# Scrape movies
source("../scripts/scrapping_functions/scrape_movies.R")
#movies <- scrape_movies (n = 10,min_number_votes = 1e4,print_progress =TRUE)
load("../data/cleaned_data/full_IMDb_Scrape.Rdata")#data name movies

# set NA number of votes to 0
movies[is.na(movies$votes),"votes"] <- 0

#Pick a cut-off point
a <- movies |>
  mutate(bin = (votes %/% 250+1)*250 ) |> #bin size of 250
  select(bin,rating) |> 
  group_by(bin) |>
  summarise(avg_rating = mean(rating,na.rm = T)) |>
  ggplot(aes(x=bin,y=avg_rating))+
  labs(title = "A logarithmic trend can be observed after excluding movies with less than 10k votes"
       ,x="Number of Votes", y = "Average Rating") +
  geom_point()+
  geom_smooth()+
  scale_x_continuous(breaks = seq(0,3e6,600000))+
  scale_y_continuous(limits = c(0,10),breaks = seq(0,10,2))+
  theme_minimal()


b <- movies |>
  mutate(bin = (votes %/% 250+1)*250 ) |> #bin size of 250
  select(bin,rating) |> 
  group_by(bin) |>
  summarise(avg_rating = mean(rating,na.rm = T)) |>
  ggplot(aes(x=bin,y=avg_rating))+
  labs(x="Number of Votes", y = "Average Rating") +
  geom_point()+
  geom_point(col="red",data = movies |>
                              mutate(bin = (votes %/% 250+1)*250 ) |> #bin size of 250
                              select(bin,rating) |> 
                              group_by(bin) |>
                              summarise(avg_rating = mean(rating,na.rm = T)) |>
                              filter(bin<=10000))+
  geom_smooth()+
  coord_cartesian(xlim = c(0, 180000))+
  scale_y_continuous(limits = c(0,10),breaks = seq(0,10,2))+
  geom_vline(xintercept = 10000,linetype = "dashed")+
  theme_minimal()
  
(a | b)

```
Conclusion: cut-off at 10k




inflation source:
The Consumer Price Index (CPI) is a measure of the average change over time in the prices paid by urban consumers for a market basket of consumer goods and services. It is an accurate representation of inflation changes over the years.

Content
This dataset contains monthly CPI indexes from 1913 to 2022 (April). May through December 2022 information is not available, but I will update that as soon as it comes out.

Acknowledgement
Thanks to the US Bureau of Labor for making CPI data available. https://www.bls.gov/cpi/



* Wrangling/cleaning
Rather scrapping, wrangling and cleaning


```{r, echo = FALSE, message = FALSE}
# Read other data

movies <- movies |>
  filter(votes>=10000)


# Source relevant scripts
source("../scripts/scrapping_functions/enrich_dob.R")
source("../scripts/scrapping_functions/enrich_studio_and_budget.R")


# Load and aggregate data switch load with functions to try on new data set

#dob_table_stars <- find_dob( movies |> select(stars) |>
#                       separate_rows(stars, sep = ",\\s*")|>
#                       unique())
load("../data/scrapped_data/dob_stars10k.Rdata")#data name dob_table_stars


#dob_table_directors <- find_dob( movies |> select(directors) |>
#                       separate_rows(directors, sep = ",\\s*")
#                       |> unique())
load("../data/scrapped_data/dob_directors10k.Rdata")#data name dob_table_directors


#studio_and_budget <- enrich_studio_and_budget(movies[,c("title","year")])
load("../data/scrapped_data/studio_and_budget10k.Rdata")#data name dob_table_directors


#source("../scripts/cleaning_functions/clean_studio_budget.R")
load("../data/cleaned_data/studio_and_budget10k_cleaned.Rdata")


#source("clean_movies") TODO
movies$genre <- str_squish(movies$genre) #will be done in scraping


# Apparently the dot operator needs %>% not yet implemented in base r using |>
CPI <- read.csv("../data/cleaned_data/inflation.csv") %>%
    mutate(CPI = rowMeans(.[,3:14],na.rm=T)) %>%
    select(Year,CPI) %>%
    rbind(data.frame(Year = 2023,CPI = 302.340)) #US Federal Reserve Economic Data


#aggregate data + make it TIDY (Split per per Genre, Actor, Director and Studio)
suppressWarnings({
movies <- movies |> 
  left_join(CPI,join_by(year==Year)) |>
  left_join(studio_and_budget, join_by(title,year)) |>
  separate_rows(stars, sep = ",\\s*") |>
  left_join(dob_table_stars,join_by(stars)) |>
  separate_rows(directors, sep = ",\\s*") |>
  left_join(dob_table_directors,join_by(directors)) |>
  separate_rows(genre, sep = ",\\s*") |>
  separate_rows(studio, sep = ",\\s*")
})



```



* (new) Data Transformations
- certificate->age dependent
- gross adjusted for inflation (time series to justify why we should account for inflation) 
- Budget adjusted for inflation (time series ,, ,, ,, ...)
- Ticket sold estimate (current ticket price?)



```{r}
#load inflation data + other relevant data sets to make new columns
movies$gross_inflation_adjusted <- "TODO"


```

